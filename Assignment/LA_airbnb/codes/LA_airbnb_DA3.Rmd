---
title: "`DA3-HW1`"
author: "2000692"
params:
  dynamictitle: Predicting Airbnb Apartment Prices in Los Angeles
  viridis_palette: viridis
output:
  html_document:
    highlighter: null
    theme: "flatly"
    code_download: TRUE
    toc: TRUE 
    toc_float: TRUE
---

# Abstract

Suppose that in Los Angeles, you have a company operating small and mid-sized apartments holding 2-6 people, and now you have a several sets of new apartment to promote on the market. How will you properly price them so that each apartment can be rented out at fair returns?

# Introduction

This passage based on data from **InsideAirBnb**, Los Angeles, on 02 January, 2021, helps predict the rental price of apartments which can accommodate 2-6 people, using machine learning tools including OLS, LASSO algorithm and Random Forest. Our research result will give reference for airbnb hosts and real estate mediators on house renting business in Los Angles.

# Data Preparation

We concentrate on Airbnb listing prices of Los Angeles, on 02 January, 2021. We retrieved the data from **InsideAirBnb**, which include indicators such as listing price, room type, amenities available, minimum nights required and so forth. The original data set has 32175 observations, and after cleaning, we have 9386 observations and more than 120 variables to present the property of each listing. The data cleaning process is as follows:

* Filtering listing accommodating capacity, only size between 2 and 6 are chosen.
* simplify property and room to 3-4 types, and make them categorical variables.
* change continuous columns (such as response rate and price) as numerical variables.
* split column "amenities" into more columns, so that each column represent one facility (e.g. coffee machine) of the original "amenities" column.
* make all facility columns as dummy variables, combined with categorical and continuous variables, to form a clean data set for subsequent analysis.
* check missing values of all columns, delete observations with missing values in price and replace other columns with the mean value.

These data were scraped from the official Airbnb website by InsideAirBnb professionals, and thus have quite high quality, so measurement error can be neglected. And also, we are confident that the data represents the current status of apartment renting market in Los Angles.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())

# load necessary packages
library(stargazer)
library(Hmisc)
library(skimr)
library(tidyverse)
library(moments)
library(lspline)
library(estimatr)
library(pander)
library(data.table) # create table to hold all info
library(dplyr) #clean data in the dataframe
library(ggplot2) # to draw plots
library(stringr) # intercept characters from a tring
library(ggExtra) # make extra plots
library(tidyr) # wrangle dataframe
require(scales) # change the scale of axis in plots
library(ggthemes) # change the themes of plots
library('knitr') # to make the screenshot of data frame prettier
library(kableExtra)
library("huxtable")
library(jtools)   
library(caret)
library(grid)
library(glmnet)
library(xtable)
library(directlabels)
library(knitr)
library(cowplot)
library(rattle)
library(ranger)

#location folders
dir <- "~/Desktop/ECBS-5208-Coding-1-Business-Analytics/Assignment/LA_airbnb"

data_in <- paste0(dir,"/raw/")
data_out <- paste0(dir,"/clean/")

# retrieve data from raw/ folder
data <- read.csv(paste0(data_in, "LA_listings.csv"))

# take a look at all columns and tag unnecessary ones.
glimpse(data)
drops <- c("host_thumbnail_url","host_picture_url","listing_url", "picture_url","host_url",
           "last_scraped","description", "neighborhood_overview", 'scrape_id',
            "host_about", "host_response_time", "name", "host_location")

# drop useless columns
data <- data[ , !(names(data) %in% drops)]
              
#drop broken lines - where id is not a character of numbers
data$junk <- grepl("[[:alpha:]]", data$id)

data <- subset(data, data$junk==FALSE)
data <- data[1:ncol(data)-1]

#display the class and type of each columns
sapply(data, class)
sapply(data, typeof)

## choose listings that can hold 2-6 persons
table(data$accommodates)
data <- data %>% filter(between(accommodates, 2, 6))

## filter apartments
data %>% group_by(property_type) %>% summarise(n=n()) %>% arrange(-n)

data <- data %>% 
  filter(str_detect(property_type, "apartment|apt"))

# rename apartment types
data <- data %>%
  mutate(property_type = ifelse(str_detect(property_type, "Entire"), "Entire_apt", 'Room_apt'))

table(data$property_type)

data <- data %>%
  mutate( f_property_type = factor(property_type))

#remove percentage signs
for (perc in c("host_response_rate","host_acceptance_rate")){
  data[[perc]]<-gsub("%","",as.character(data[[perc]]))
}

#remove dollar signs from price variables
for (pricevars in c("price")){
  data[[pricevars]]<-gsub("\\$","",as.character(data[[pricevars]]))
  data[[pricevars]]<-as.numeric(as.character(data[[pricevars]]))
}

#format binary variables
for (binary in c("host_is_superhost","host_has_profile_pic","host_identity_verified",
                 "instant_bookable", "has_availability")){
  data[[binary]][data[[binary]]=="f"] <- 0
  data[[binary]][data[[binary]]=="t"] <- 1
}

df2 <- data

# first create unique list of all amenities in the df2
amenities_unique <- 
  unique(
    unlist(
      df2$amenities %>% str_extract_all('(?<=")(\\w+\\s*\\w*)(?=")')
    )
  )
# then iterate over the list and create a new column for each unique amenity and fill values with this logic:
# in the new column, if the amenity is detected as a string in the original "amenities" at this row, set value to 1
# else set value to 0
for (i in amenities_unique){
  df2 <- 
    df2 %>% 
    mutate(!! i := ifelse(str_detect(amenities, !! i), 1, 0))
}


df2 <- df2 %>% rename( refrigerator1 = `Kitchenaide refrigerator` ,
                Coffee_maker = `Nespresso machine` , 
                bread_maker = Toaster ,
                Barbecue_tool = `BBQ grill` )

column_names <- c('refrigerator', 'TV', 'stove', 'shampoo','conditioner',
                  'wifi', 'tub','oven', 'kitchen', 'heating', 'coffee', 'bread', 'barbecue')


# categorize dummy variables generated from the amenities
for( word in column_names){
  # Subset columns which contains a specific word and save them to another dataframe. Also select 'id' to use for merge later
  new_df <- df2 %>% select(contains(word),"id")
  #Go row by row to see if any of the rows have at least one '1'. If it does, populate new column 'col_name' with 1
  new_df$col_name <- apply(new_df[0:ncol(new_df)], 1, function(x) ifelse(any(x == 1), '1', '0'))
  # Save new column and id column to another dataframe. We use this new dataframe to merge with original dataframe
  new_df_merge <- new_df %>% select(id,col_name)
  #merge original dataframe and new_df_merge by 'id'
  df2 <- merge(df2, new_df_merge,by = "id", all = FALSE)
  #remove the new column and 'id' column from the new_df dataframe
  new_df <- new_df %>% select(-c(id,col_name))
  # Remove the subset columns from original dataframe since they have already been aggregated into a new column and merged
  df2 <- df2 %>% select(-colnames(new_df))
  names(df2)[names(df2) == 'col_name'] <- paste0(word,"_agg")
}

df2 <- df2[ , colSums(is.na(df2)) < nrow(df2)] # remove columns that are all N/As
table(colSums(is.na(df2)) == nrow(df2))

# rename certain columns
data <- df2 %>% rename(coffee_maker = coffee_agg, 
               bread_maker = bread_agg,
               barbecue_tool = barbecue_agg)


setwd("/Users/wodediannao/desktop/da_case_studies/")

# set data dir, load theme and functions
source("ch00-tech-prep/theme_bg.R")
source("ch00-tech-prep/da_helper_functions.R")

# data used
source("set-data-directory.R") 

output <- paste(dir, "out/", sep = "/") # path for case studies (extensive folders)
create_output_if_doesnt_exist(output) # customized function

options(digits = 3)


table(data$property_type)  # a glimpse of this column (check the sorts and size of each type)


#Room type as factor
table(data$room_type) # like "group_by"

data <- data %>%
  mutate(f_room_type = factor(room_type)) # still don't understand

# Rename room type because it is too long (nested structure)
data$f_room_type2 <- factor(ifelse(data$f_room_type== "Entire home/apt", "Entire/Apt",
                                   ifelse(data$f_room_type== "Private room", "Private",
                                          ifelse(data$f_room_type== "Shared room", "Shared", "."))))

## Create Numerical variables
data <- data %>%
  mutate(usd_price_day = price,
    p_host_response_rate = as.numeric(host_response_rate))

# add new numerical columns from certain columns

numericals <- c("accommodates", 'bedrooms', 'beds', 
                "review_scores_rating", "number_of_reviews", "reviews_per_month", 
                "minimum_nights", 'host_total_listings_count')

# table(numericals %in% colnames(data))

data <- data %>% # a little bit like "lapply"
  mutate_at(vars(numericals), funs("n"=as.numeric)) # A list of columns generated by vars()
# A function fun 


# rename columns so they start with n_ as opposed to end with _n
nnames <- data %>%
  select(ends_with("_n")) %>%
  names()

nnames_i <- match(nnames, colnames(data))
colnames(data)[nnames_i] <- paste0("n_", numericals)


#create days since first review
data <- data %>%
  mutate(
    n_days_since = as.numeric(as.Date(calendar_last_scraped,format="%Y-%m-%d") -
                                as.Date(first_review ,format="%Y-%m-%d")))
# change location of certain columns
data <- data %>% relocate(host_is_superhost, host_has_profile_pic, host_identity_verified,
                  has_availability, instant_bookable, .before = f_room_type)
# create dummy vars
dummies <- names(data)[seq(56,144)]
data <- data %>%
  mutate_at(vars(dummies), funs("d"= (.)))
# rename columns
dnames <- data %>%
  select(ends_with("_d")) %>%
  names()

dnames_i <- match(dnames, colnames(data))
colnames(data)[dnames_i] <- paste0("d_", tolower(gsub("[^[:alnum:]_]", "",dummies)))
# keep columns if contain d_, n_,f_, p_, usd_ and some others
data <- data %>%
  select(matches("^d_.*|^n_.*|^f_.*|^p_.*|^usd_.*"), price, id, neighbourhood_cleansed, 
         room_type,property_type)

# with price info only
data <- data %>%
  drop_na(price)

write_csv(data, paste0(data_out, "airbnb_LA_workfile.csv"))
```

# EDA and Feature Engineering

## Quick look at price

In this part, we check the summary statistics of defendant variable and some explanatory variables using domain knowledge, and decide which variable to add in our trial models. Also, we draw box plots of certain variables, to find possible interaction betweeen them.

The rental price here is US dollars, and we start with its summary statistics and histogram:


```{r echo=F, warning=FALSE, warning=FALSE, message=FALSE}
data <- read_csv(paste0(data_out, "airbnb_LA_workfile.csv"))
df1 <- data

summary_price <- data %>% summarise(
  Varible      = 'price',
  n_observation = sum( !is.na( price ) ),
  Mean     = round(mean(price),digits = 2),
  Median   = median(price),
  Min      = min(price),
  Max      = max(price),
  Std.      = round(sd(price),digits = 2),
  Skew     = round(skewness(price),digits = 2)) %>% as.data.frame()

summary_price  %>% kable(caption = "Summary Statistics of Apartment Price") %>%
  kable_styling(full_width = T) %>% 
   kable_classic(html_font = "Cambria")
```


From the statistics table and Figure1., we can see that apartment price is hugely skewed with a long right tail: there are several outliers exceeding 900 dollars, which fall outside the 95% percentile of the data. Considering the proportion of these extreme values, we decide to drop values larger than 375 or smaller than 20 dollars (this [20, 375] range includes 95% of the data), and take natural logs of price.

```{r echo=F, warning=FALSE, warning=FALSE, message=FALSE ,out.width= "50%"}
data <- data %>%
  mutate(ln_price = log(price))

ggplot(data, aes(price)) +
  geom_histogram(binwidth = 25, fill = color[5], color = color.outline, alpha = 0.8, size = 0.25) +
  theme_bg() +
  labs( caption = "Figure 1. Histogram of Price",x='Price (USD)',y='Number of Observations') +
  theme(plot.caption = element_text(hjust = 0, face= "italic"),
        plot.title.position = "plot",
        plot.caption.position =  "plot")

# Remove extreme values + missing from prices (this case: only 3 missing values)
data <- data %>%
  filter(price <= 375, price >= 20 ) 

# Histograms
ggplot(data, aes(ln_price)) +
  geom_histogram(binwidth = 0.1, fill = color[5], color = color.outline, alpha = 0.8, size = 0.25) +
  theme_bg() +
  labs( caption = "Figure 2. Histogram of Price",x='Price (USD, in scale)',y='Number of Observations') +
  theme(plot.caption = element_text(hjust = 0, face= "italic"),
        plot.title.position = "plot",
        plot.caption.position =  "plot")
```

Check Figure 2., we find that ln_price is nearly normal distributed; we will keep this log variable for further analysis.

## Explanatory Variables

We pay special attention to some key explanatory variables (i.e. accommodate capacity, number of beds, number of reviews and so forth) and check their distribution. Similar to how we deal with price variable, we remove extreme values and take natural logarithm if these variables are skewed with a long right tail. We also take square form of accommodate and its logarithm to approximate a subsequent polynomial pattern between price and accommodate capacity variable.

Furthermore, we name one more categorical variable: minimum nights allowed. We check its distribution and split the variable into three slots:[0, 4], [4, 135] and [135, max], which respectively represent 50%, 95% and the rest of the variable distribution.

```{r, include=FALSE}
## n_accomodates: look at distribution

data %>%
  group_by(n_accommodates) %>%
  summarise(mean_price = mean(price), min_price= min(price), max_price = max(price), n = n())

# Squares and further values to create
data <- data %>%
  mutate(n_accommodates2 = n_accommodates^2, ln_accommodates=log(n_accommodates) ,
         ln_accommodates2=log(n_accommodates)^2)

## Beds
data %>%
  group_by(n_beds) %>%
  summarise(mean_price = mean(price), min_price= min(price), max_price = max(price), n = n())

# maybe best is to have log beds
data <- data %>%
  mutate(ln_beds = log(n_beds))

summary(data$n_number_of_reviews)
describe(data$n_number_of_reviews)

# number of reviews: use logs as well
data <- data %>%
  mutate(ln_number_of_reviews = log(n_number_of_reviews+1))

# Pool num of reviews to 3 categories: none, 1-135 and >135
data <- data %>%
  mutate(f_number_of_reviews = cut(n_number_of_reviews, c(0,4,135,max(data$n_number_of_reviews)), 
                                   labels=c(0,4,135), right = F))
data %>%
  group_by(f_number_of_reviews) %>%
  summarise(median_price = median(price) ,mean_price = mean(price) ,  n=n())

## Time since
# Create variables, measuring the time since: squared, cubic, logs
data <- data %>%
  mutate(
    ln_days_since = log(n_days_since),
    ln_days_since2 = log(n_days_since)^2,
    ln_days_since3 = log(n_days_since)^3 ,
    n_days_since2=n_days_since^2,
    n_days_since3=n_days_since^3)

# Check the effect
lndays_plot <- data %>%
  filter(data$price<= 375, ln_days_since>2)

skimr::skim(data$n_number_of_reviews)

# Create log of review scores
data <- data %>%
  mutate(ln_review_scores_rating = log(n_review_scores_rating))
# Regression 1) ln price - num of review scores
lm(ln_price ~ n_review_scores_rating,data=data)
# Regression 2) ln price - log num of review scores
lm(ln_price ~ ln_review_scores_rating,data=data)
#leave as is

## minimum nights
lm(ln_price ~ n_minimum_nights,data=data)

describe(data$n_minimum_nights)
# Pool and categorize the number of minimum nights: 1,30, 30+

data <- data %>%
  mutate(f_minimum_nights= cut(n_minimum_nights, c(1,30,max(data$n_minimum_nights)), labels=c(1,30), right = F))

lm(ln_price ~ f_minimum_nights,data=data)

categoricals <- c("f_property_type", "f_room_type")


for (i in 1:length(categoricals)) {
  data %>%
    group_by(get(categoricals[i])) %>%
    summarise(mean_price = mean(price) ,  n=n()) %>%
    print
}
#####################################

# Change Infinite values with NaNs
for (j in 1:ncol(data) ) data.table::set(data, which(is.infinite(data[[j]])), j, NA)

write_csv(data, paste0(data_out, "airbnb_LA_workfile_adj.csv"))
```

```{r, include=FALSE}
data <-
  read_csv(paste0(data_out, "airbnb_LA_workfile_adj.csv")) %>%
  mutate_if(is.character, factor)
# where do we have missing variables now?
to_filter <- sapply(data, function(x) sum(is.na(x))) # what's function(x)?
to_filter[to_filter > 0]

# what to do with missing values?
# 1. drop if no target (already did)
data <- data %>%
  drop_na(price)


# 2. imput when few, not that important
data <- data %>%
  mutate(
    n_beds = ifelse(is.na(n_beds), n_accommodates, n_beds), #assume n_beds=n_accomodates
    f_minimum_nights=ifelse(is.na(f_minimum_nights),1, f_minimum_nights),
    f_number_of_reviews=ifelse(is.na(f_number_of_reviews),1, f_number_of_reviews),
    ln_beds=ifelse(is.na(ln_beds),0, ln_beds)
  )

# 3. drop columns when many missing not important
to_drop <- c("p_host_response_rate", "n_reviews_per_month")
data <- data %>%
  select(-one_of(to_drop))

to_filter <- sapply(data, function(x) sum(is.na(x)))
to_filter[to_filter > 0]


# 4. Replace missing variables re reviews with zero, when no review + add flags
data <- data %>%
  mutate(
    n_days_since =  ifelse(is.na(n_days_since), median(n_days_since, na.rm = T), n_days_since),
    flag_days_since=ifelse(is.na(n_days_since),1, 0),
    flag_review_scores_rating=ifelse(is.na(n_review_scores_rating),1, 0),
    n_review_scores_rating =  ifelse(is.na(n_review_scores_rating), median(n_review_scores_rating, na.rm = T), n_review_scores_rating),
    n_bedrooms =  ifelse(is.na(n_bedrooms), median(n_bedrooms, na.rm = T), n_bedrooms),
    flag_n_bedrooms =ifelse(is.na(n_bedrooms),1, 0)
  )


table(data$flag_days_since)

# Look at data
summary(data$price)

# where do we have missing variables now?
(to_filter <- sapply(data, function(x) sum(is.na(x))))
to_filter[to_filter > 0]
```
In the end, we check the data again and do some housekeeping work by changing all infinite values in all columns as N/A values, which are generated from taking logs.

```{r echo=F, warning=FALSE, warning=FALSE, message=FALSE ,out.width= "25%"}
ggplot(data = data, aes(x=n_accommodates, y=price)) +
  geom_point(size=1, colour=color[3], shape=16)+
  ylim(0,400)+
  xlim(1,7)+
  geom_smooth(method="lm", colour=color[1], se=FALSE)+
  theme_bg() +
  labs( caption = "Figure 3. Apartment Price and Accommodation Capacity: a scatter plot",x='Number of people accommodated',y='Price(USD)') + theme(plot.caption = element_text(hjust = 0, face= "italic"),
        plot.title.position = "plot",
        plot.caption.position =  "plot")

## Number of reviews
nreview_plot <- data %>%
  filter(n_number_of_reviews < 135, n_number_of_reviews > 0)


ggplot(data, aes(ln_number_of_reviews)) +
  geom_histogram(binwidth = 0.6, fill = color[1], color = color.outline, alpha = 0.8, size = 0.25) +
  theme_bg() +
  labs( caption = "Figure 4. Histogram of Ln_review",x="Log N of reviews",y='Number of Observations') + theme(plot.caption = element_text(hjust = 0, face= "italic"),
        plot.title.position = "plot",
        plot.caption.position =  "plot")


ggplot(data = data, aes(x=n_number_of_reviews , y=price)) +
  geom_point(size=1.5, colour=color[3], shape=4) +
  ylim(25,250)+
  xlim(0,140)+
  geom_smooth(method="loess", colour=color[1], se=F)+
  theme_bg() +
  labs( caption = "Figure 5. Apartment Price and Number of Reviews: a scatter plot",x=" Number of reviews",y="Price(USD)") + 
  theme(plot.caption = element_text(hjust = 0, face= "italic"),
        plot.title.position = "plot",
        plot.caption.position =  "plot")

#-Inf values
#lm(ln_price ~ ln_days_since + ln_days_since2 + ln_days_since3, data=data)

## review score effect
ggplot(data = data, aes(x=n_review_scores_rating , y=price)) +
  geom_point(size=1.5, colour=color[3], shape=4) +
  ylim(0,400)+
  xlim(20,100)+
  geom_smooth(method="loess", colour=color[1], se=F)+
  theme_bg() +
  labs( caption = "Figure 6. Apartment Price and Review Score: a scatter plot",x="Review score",y= 'Daily price (USD)') + 
  theme(plot.caption = element_text(hjust = 0, face= "italic"),
        plot.title.position = "plot",
        plot.caption.position =  "plot")

```

# Model Building, Prediction and Model Selection
## Variable Categorization

Now we have 122 variables, and it seems physical demanding and confusing to add them one by one to our model. So, we categorize them into four groups:

* Basic Variables: include basic key variables such as accommodate capacity, number of beds, property type and room type.
* Factorized variables: number_of_reviews, review scores and flag of review scores.
* Higher-order variables: square form of accommodate capacity, square and cubic form of days since last scraped the information.
* Dummy variables: facilities included in amenities and original binary variables such as "if hose is super host".

```{r, include=FALSE}
# Basic Variables
basic_lev  <- c("n_accommodates", "n_beds", "f_property_type", "f_room_type", "n_days_since", "flag_days_since")
# poly_lev %in% colnames(data)

# Factorized variables
reviews <- c("f_number_of_reviews","n_review_scores_rating", "flag_review_scores_rating")
# Higher orders
poly_lev <- c("n_accommodates2", "n_days_since2", "n_days_since3")

#not use p_host_response_rate due to missing obs

# Dummy variables: Extras -> collect all options and create dummies
amenities <-  grep("^d_.*", names(data), value = TRUE)
```

## Interaction

Also, we wonder whether there are certain interactions among variables, and thus we choose several dummy variables to interact with our factorised variables such as room types. As shown in the chart, the average price moves up and down when room type changes and when dummy variables take different values, which is also our criterion to choose certain variables for interaction: whether these variables significantly changes apartment price. We will add these interaction part in subsequent models.

```{r echo=F, warning=FALSE, warning=FALSE, message=FALSE}
#Look up room type interactions
p1 <- price_diff_by_variables2(data, "f_room_type", "d_instant_bookable", "Room type", "instant_bookable")
p2 <- price_diff_by_variables2(data, "f_room_type", "f_property_type", "Room type", "Property type")

#Look up property type
p3 <- price_diff_by_variables2(data, "f_property_type", "d_airconditioning", "Property type", "Air-conditioning")
p4 <- price_diff_by_variables2(data, "f_property_type", "d_wifi_agg", "Property type", "Wifi_available")
p5 <- price_diff_by_variables2(data, "f_property_type", "d_bread_maker", "Property type", "bread_maker")
p6 <- price_diff_by_variables2(data, "f_property_type", "d_trashcompactor", "Property type", "trashcompactor")

plot_grid(p1, p2, p3, p4,p5, p6, nrow=3, ncol=2)

# dummies suggested by graphs
X1  <- c("f_room_type*f_property_type",  "f_room_type*d_instant_bookable")

# Additional interactions of factors and dummies
X2  <- c("d_wifi_agg*f_property_type", "d_bread_maker*f_property_type", "d_trashcompactor*f_property_type")
X3  <- c(paste0("(f_property_type + f_room_type) * (",
                paste(amenities, collapse=" + "),")"))
```

## Model and Sub-models
After all previous steps, we now have 9386 observations, in which 20% will be randomly chosen as holdout set and the rest with 7509 observations will used for 5-fold cross validation (incl. training and test sets). We opt for three models: OLS regression model, LASSO and Random Forest. We will start one by one and assess their prediction performance. 


### OLS 
For OLS linear regression we have specified 8 models for predicting price. Note that all models take Log price as target variable, and as we move ahead, each model will become more sophisticated as more explanatory variables and interactions join. The predictor variables included in the 8 regression models are shown in table 2.

```{r, include=FALSE}
# Create models in levels models: 1-8
modellev1 <- " ~ n_accommodates"
modellev2 <- paste0(" ~ ",paste(basic_lev,collapse = " + "))
modellev3 <- paste0(" ~ ",paste(c(basic_lev,reviews),collapse = " + "))
modellev4 <- paste0(" ~ ",paste(c(basic_lev,reviews,poly_lev),collapse = " + "))
modellev5 <- paste0(" ~ ",paste(c(basic_lev,reviews,poly_lev,X1),collapse = " + "))
modellev6 <- paste0(" ~ ",paste(c(basic_lev,reviews,poly_lev,X1,X2),collapse = " + "))
modellev7 <- paste0(" ~ ",paste(c(basic_lev,reviews,poly_lev,X1,X2,amenities),collapse = " + "))
modellev8 <- paste0(" ~ ",paste(c(basic_lev,reviews,poly_lev,X1,X2,amenities,X3),collapse = " + "))
```

```{r, include=FALSE}
# Separate hold-out set #
#################################

# create a holdout set (20% of observations)
smp_size <- floor(0.2 * nrow(data))

# Set the random number generator: It will make results reproducible
set.seed(20210202)

# create ids:
# 1) seq_len: generate regular sequences
# 2) sample: select random rows from a table
holdout_ids <- sample(seq_len(nrow(data)), size = smp_size)
data$holdout <- 0
data$holdout[holdout_ids] <- 1

#Hold-out set Set
data_holdout <- data %>% filter(holdout == 1)

#Working data set
data_work <- data %>% filter(holdout == 0)


##############################
#      cross validation      #
##############################

## N = 5
n_folds=5
# Create the folds
set.seed(20210202)

folds_i <- sample(rep(1:n_folds, length.out = nrow(data_work) ))
# Create results
model_results_cv <- list()


for (i in (1:8)){
  model_name <-  paste0("modellev",i)
  model_pretty_name <- paste0("(",i,")")
  
  yvar <- "ln_price"
  xvars <- eval(parse(text = model_name))
  formula <- formula(paste0(yvar,xvars))
  
  # Initialize values
  rmse_train <- c()
  rmse_test <- c()
  
  model_work_data <- lm(formula,data = data_work)
  BIC <- BIC(model_work_data)
  nvars <- model_work_data$rank -1
  r2 <- summary(model_work_data)$r.squared
  
  # Do the k-fold estimation
  for (k in 1:n_folds) {
    test_i <- which(folds_i == k)
    # Train sample: all except test_i
    data_train <- data_work[-test_i, ]
    # Test sample
    data_test <- data_work[test_i, ]
    # Estimation and prediction
    model <- lm(formula,data = data_train)
    prediction_train <- predict(model, newdata = data_train)
    prediction_test <- predict(model, newdata = data_test)
    
    # Criteria evaluation
    rmse_train[k] <- mse_lev(prediction_train, data_train[,yvar] %>% pull)**(1/2)
    rmse_test[k] <- mse_lev(prediction_test, data_test[,yvar] %>% pull)**(1/2)
    
  }
  
  model_results_cv[[model_name]] <- list(yvar=yvar,xvars=xvars,formula=formula,model_work_data=model_work_data,
                                         rmse_train = rmse_train,rmse_test = rmse_test,BIC = BIC,
                                         model_name = model_pretty_name, nvars = nvars, r2 = r2)
}

model <- lm(formula,data = data_train)
prediction_train <- predict(model, newdata = data_train)
prediction_test <- predict(model, newdata = data_test)

skim(data_train$ln_days_since)

t1 <- imap(model_results_cv,  ~{
  as.data.frame(.x[c("rmse_test", "rmse_train")]) %>%
    dplyr::summarise_all(.funs = mean) %>%
    mutate("model_name" = .y , "model_pretty_name" = .x[["model_name"]] ,
           "nvars" = .x[["nvars"]], "r2" = .x[["r2"]], "BIC" = .x[["BIC"]])
}) %>%
  bind_rows()
t1
column_names <- c("Model", "N predictors", "R-squared", "BIC", "Training RMSE",
                  "Test RMSE")

# Nice table produced and saved as .tex without \beign{table}
# -R2, BIC on full work data-n.
# -In sample rmse: average on training data; avg test : average on test data

t14_2 <- t1 %>%
  select("model_pretty_name", "nvars", "r2" , "BIC", "rmse_train", "rmse_test")
colnames(t14_2) <- column_names



# RMSE training vs test graph
t1_levels <- t1 %>%
  dplyr::select("nvars", "rmse_train", "rmse_test") %>%
  gather(var,value, rmse_train:rmse_test) %>%
  mutate(nvars2=nvars+1) %>%
  mutate(var = factor(var, levels = c("rmse_train", "rmse_test"),
                      labels = c("RMSE Training","RMSE Test")))

```

```{r echo=F, warning=FALSE, warning=FALSE, message=FALSE }
model_brf <- tibble("Model" = paste0("M",1:8), 
       "Predictor Variables" = c(" ~ n_accommodates", 
                                 " ~ M1 + n_beds, f_property_type, f_room_type, n_days_since, flag_days_since",
                                 " ~ M2 + f_number_of_reviews, n_review_scores_rating, flag_review_scores_rating",
                                 " ~ M3 + n_accommodates2, n_days_since2, n_days_since3",
                                 " ~ M4 + f_room_type×f_property_type, f_room_type×d_instant_bookable",
                                 " ~ M5 + d_wifi_agg×f_property_type, d_bread_maker×f_property_type, d_trashcompactor×f_property_type",
                                 " ~ M6 + All amenities",
                                 " ~ M7 + interaction of amenities and property and room types"), 
       'N Var' = t1$nvars)

model_brf  %>% kable(caption = 'Table 2: Versions of the Airbnb apartment price prediction models') %>% kable_styling(full_width = T) %>%  kable_classic(html_font = "Cambria")

```

First, we estimate all regressions using all observations in the work set and calculate R-squared and BIC. Then, we estimated the models again using 5-fold cross-validation: for each fold, we estimated the regression using the training set, and used it for prediction not only in the training set but also in the corresponding test set. Finally, we collect RMSE for each model as means to assess each modal performance. 

Table 3 shows the number of variables, R-squared, BIC, and cross-validated training set and test set RMSE for the eight regressions. 

```{r  echo=F, warning=FALSE,  message=FALSE}
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80), tidy=TRUE)
t14_2 %>% kable(caption = 'Table 3: Comparing Model Fit Measures') %>% 
  kable_styling(full_width = T) %>%  kable_classic(html_font = "Cambria")

```

R-squared in the work set keeps increasing as more and more predictor variables are added and the most complex model explains 47% of the variation in prices. However, the BIC shows an first downward but then upward trend throughout models. According to the BIC, the best model is regression M7, while the most complex model M8 have a high risk of overly fitting the data. 

RMSE in the training sets keeps improving with model complexity. The test set RMSE improves too, until M7, but it is substantially worse for the more complex M8. Thus, M7 produces the lowest test RMSE, with a value of 0.347. 

In a word, both BIC and cross-validation produce unanimous results, which picks model M7.

### LASSO

The LASSO algorithm is completely automated in R, and all we have to do is specify a regression with a large set of starting predictor variables, and push the run button. Thus, the most important task is specifying the set of candidate x variables. Here we start with the variables in our Model 8, which includes all of the variables.
```{r include=FALSE}
# take model 8 (and find observations where there is no missing data)may
vars_model_7 <- c("price", basic_lev,reviews,poly_lev,X1,X2,amenities)
vars_model_8 <- c("price", basic_lev,reviews,poly_lev,X1,X2,amenities,X3)

# Set lasso tuning parameters
train_control <- trainControl(method = "cv", number = n_folds)
tune_grid <- expand.grid("alpha" = c(1), "lambda" = seq(0.05, 1, by = 0.05))

# We use model 7 without the interactions so that it is easy to compare later to post lasso ols
formula <- formula(paste0("ln_price ~ ", paste(setdiff(vars_model_8, "ln_price"), collapse = " + ")))

set.seed(1234)
lasso_model <- caret::train(formula,
                            data = data_work,
                            method = "glmnet",
                            preProcess = c("center", "scale"),
                            trControl = train_control,
                            tuneGrid = tune_grid,
                            na.action=na.exclude)

print(lasso_model$bestTune$lambda)

lasso_coeffs <- coef(lasso_model$finalModel, lasso_model$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var = "variable") %>%
  rename(coefficient = `1`)  # the column has a name "1", to be renamed

print(lasso_coeffs)

lasso_coeffs_nz<-lasso_coeffs %>%
  filter(coefficient!=0)
print(nrow(lasso_coeffs_nz))

# Evaluate model. CV error:
lasso_cv_rmse <- lasso_model$results %>%
  filter(lambda == lasso_model$bestTune$lambda) %>%
  dplyr::select(RMSE)
print(lasso_cv_rmse[1, 1])
```

#### Prediction Result

We ran the LASSO algorithm with 5-fold cross-validation for selecting the optimal value for λ. In the end, LASSO returns with an estimated regression that has fewer coefficients: it chooses zero for some of the coefficients, which practically means dropping the corresponding variables from the regression. For the variables that it retains, LASSO gives estimated coefficients. 
```{r echo=FALSE, message=FALSE, warning=FALSE}
lasso_coeffs$RMSE <- "0.137"
kbl(head(lasso_coeffs ,6))  %>% 
  kable_styling(full_width = T) %>%
  row_spec(3, color = "grey") %>% 
 kable_classic(html_font = "Cambria") 
```

From above table, we can see that the algorithm picked a regression with 2 variables. This number is quite different from the number of variables in our model M7 that cross-validation picked as the best from the eight models we specified earlier. The overall RMSE across the five test sets for the LASSO regression is 0.137. It is 0.347 for M7, suggesting that our hand-picked M7 is almost as good as the LASSO regression. 

Up till now, we prefer model M7 over LASSO, because it may be easier to explain which variables are included.

#### Diagnsotics 

```{r, include=FALSE}
###################################################
# Diagnsotics #
###################################################
model7_level <- model_results_cv[["modellev7"]][["model_work_data"]]


# look at holdout RMSE
model7_level_work_rmse <- mse_lev(predict(model7_level, newdata = data_work), data_work[,"ln_price"] %>% pull)**(1/2)
model7_level_holdout_rmse <- mse_lev(predict(model7_level, newdata = data_holdout), data_holdout[,"ln_price"] %>% pull)**(1/2)
model7_level_holdout_rmse

###################################################
# FIGURES FOR FITTED VS ACTUAL OUTCOME VARIABLES #
###################################################

# Target variable
Ylev <- data_holdout[["ln_price"]]

meanY <-mean(Ylev)
sdY <- sd(Ylev)
meanY_m2SE <- meanY -1.96 * sdY
meanY_p2SE <- meanY + 1.96 * sdY
Y5p <- quantile(Ylev, 0.05, na.rm=TRUE)
Y95p <- quantile(Ylev, 0.95, na.rm=TRUE)

# Predicted values
predictionlev_holdout_pred <- as.data.frame(predict(model7_level, newdata = data_holdout, interval="predict")) %>%
  rename(pred_lwr = lwr, pred_upr = upr)
predictionlev_holdout_conf <- as.data.frame(predict(model7_level, newdata = data_holdout, interval="confidence")) %>%
  rename(conf_lwr = lwr, conf_upr = upr)

predictionlev_holdout <- cbind(data_holdout[,c("ln_price","n_accommodates")],
                               predictionlev_holdout_pred,
                               predictionlev_holdout_conf[,c("conf_lwr","conf_upr")])


# Create data frame with the real and predicted values
d <- data.frame(ylev=Ylev, predlev=predictionlev_holdout[,"fit"] )
# Check the differences
(d$elev <- d$ylev - d$predlev)


# Redo predicted values at 80% PI
predictionlev_holdout_pred <- as.data.frame(predict(model7_level, newdata = data_holdout, interval="predict", level=0.8)) %>%
  rename(pred_lwr = lwr, pred_upr = upr)
predictionlev_holdout_conf <- as.data.frame(predict(model7_level, newdata = data_holdout, interval="confidence", level=0.8)) %>%
  rename(conf_lwr = lwr, conf_upr = upr)

predictionlev_holdout <- cbind(data_holdout[,c("ln_price","n_accommodates")],
                               predictionlev_holdout_pred,
                               predictionlev_holdout_conf[,c("conf_lwr","conf_upr")])

summary(predictionlev_holdout_pred)

predictionlev_holdout_summary <-
  predictionlev_holdout %>%
  group_by(n_accommodates) %>%
  dplyr::summarise(fit = mean(fit, na.rm=TRUE), pred_lwr = mean(pred_lwr, na.rm=TRUE), pred_upr = mean(pred_upr, na.rm=TRUE),
                   conf_lwr = mean(conf_lwr, na.rm=TRUE), conf_upr = mean(conf_upr, na.rm=TRUE))

kable(x = predictionlev_holdout_summary, format = "latex", booktabs=TRUE,  digits = 3, row.names = FALSE,
      linesep = "", col.names = c("Accomodates","Prediction","Pred. interval lower",
                                  "Pred. interval upper","Conf.interval lower","Conf.interval upper")) %>%
  cat(.,file= paste0(output, "modellev7_holdout_summary.tex"))


ggplot(predictionlev_holdout_summary, aes(x=factor(n_accommodates))) +
  geom_bar(aes(y = fit ), stat="identity",  fill = color[1], alpha=0.7 ) +
  geom_errorbar(aes(ymin=pred_lwr, ymax=pred_upr, color = "Pred. interval"),width=.2) +
  #geom_errorbar(aes(ymin=conf_lwr, ymax=conf_upr, color = "Conf. interval"),width=.2) +
  scale_y_continuous(name = "Predicted price (US dollars)") +
  scale_x_discrete(name = "Accomodates (Persons)") +
  scale_color_manual(values=c(color[2], color[2])) +
  theme_bg() +
  theme(legend.title= element_blank(),legend.position="none")
```
After estimating M7 model on all observations in the work sample, we calculated its RMSE in the holdout sample. The RMSE for M7 is 0.337. The holdout set RMSE is slightly smaller than the cross-validated RMSE, as the sample size that we use for the prediction is larger than for cross-validation. 
```{r, include=FALSE}
# Plot predicted vs price
ggplot(data = d) +
  geom_point(aes(y=ylev, x=predlev), color = color[1], size = 1,
             shape = 16, alpha = 0.7, show.legend=FALSE, na.rm=TRUE) +
  #geom_smooth(aes(y=ylev, x=predlev), method="lm", color=color[2], se=F, size=0.8, na.rm=T)+
  geom_segment(aes(x = 0, y = 0, xend = 10, yend =10), size=0.5, color=color[2], linetype=2) +
  coord_cartesian(xlim = c(2,7), ylim = c(2, 7)) +
  scale_x_continuous(expand = c(0.01,0.01),limits=c(0,10), breaks=seq(0, 10, by= 1)) +
  scale_y_continuous(expand = c(0.01,0.01),limits=c(0,10), breaks=seq(0, 10, by=1)) +
  labs(y = "Price (US dollars, in scale)", x = "Predicted price  (US dollars, in scale)") +
  theme_bg() 
```

We can show how predicted prices compare to actual prices in above y_hat vs. y graph. We can see that the prediction does a somewhat better job for lower than for higher prices. Indeed, the range of actual prices is wider than the range of predicted prices as regression models often cannot predict extreme values at ease.

### Random Forest

Random forest is an ensemble method combining the results of hundreds of imperfect regression trees to produce a better prediction. In this part, we use the same data set to execute random forest prediction. As what we did previously, we first split the sample into two sub-samples: a hold-out sample  (30%) and the work(70%, training + test) sample. For the work sample we will do 5-fold cross-validation: divide the work set into five 20% random sab-samples for test sets, and use the other 80% as a training set.

A random forest needs little tuning, just three parameters: 

* the number of bootstrap samples, 
* the number of variables considered for each split, 
* and the minimum number of observations in the terminal nodes of each tree as a stopping rule. 

For the number of bootstap draws, we went with the default option of 500. For the number of variables, we tried 8.10 and 12. For the minimum number of observations in the terminal nodes we choose 5, 10, and 15.

```{r, include=FALSE}
# copy a variable - purpose later, see at variable importance
data <- data %>% mutate(n_accommodates_copy = n_accommodates,
                        f_neighbourhood_cleansed = factor(neighbourhood_cleansed))

# create train and holdout samples -------------------------------------------
# train is where we do it all, incl CV

set.seed(2802)

# First pick a smaller than usual training set so that models run faster and check if works
# If works, start anew without these two lines

# try <- createDataPartition(data$price, p = 0.2, list = FALSE)
#data <- data[try, ]



train_indices <- as.integer(createDataPartition(data$price, p = 0.7, list = FALSE))
data_train <- data[train_indices, ]
data_holdout <- data[-train_indices, ]

dim(data_train)
dim(data_holdout)

# Define models: simpler, extended -----------------------------------------------------------

# Basic Variables inc neighnourhood
basic_vars <- c("n_accommodates", "n_beds", "n_days_since", "f_property_type","f_room_type", 
                "f_neighbourhood_cleansed")

# reviews
reviews <- c("n_number_of_reviews", "f_number_of_reviews", "n_review_scores_rating", "flag_review_scores_rating")

# reviews %in% colnames(data)

# Dummy variables
amenities <-  grep("^d_.*", names(data), value = TRUE)

#interactions for the LASSO
# from ch14
X1  <- c("n_accommodates*f_property_type",  "f_room_type*f_property_type",  "f_room_type*d_instant_bookable",
         "d_wifi_agg*f_property_type", "d_bread_maker*f_property_type", "d_trashcompactor*f_property_type")
# with boroughs
X2  <- c("f_property_type*f_neighbourhood_cleansed", "f_room_type*f_neighbourhood_cleansed",
         "n_accommodates*f_neighbourhood_cleansed" )


predictors_1 <- c(basic_vars)
predictors_2 <- c(basic_vars, reviews, amenities)
predictors_E <- c(basic_vars, reviews, amenities, X1,X2)


#########################################################################################
#
# PART II
# RANDOM FORESTS -------------------------------------------------------
#
#########################################################################################



# do 5-fold CV
train_control <- trainControl(method = "cv",
                              number = 5,
                              verboseIter = FALSE)


# set tuning
tune_grid <- expand.grid(
  .mtry = c(5, 7, 9),
  .splitrule = "variance",
  .min.node.size = c(5, 10)
)


# simpler model for model A (1)
set.seed(1234)
system.time({
  rf_model_1 <- train(
    formula(paste0("price ~", paste0(predictors_1, collapse = " + "))),
    data = data_train,
    method = "ranger",
    trControl = train_control,
    tuneGrid = tune_grid,
    importance = "impurity"
  )
})
rf_model_1

# set tuning for benchamrk model (2)
tune_grid <- expand.grid(
  .mtry = c(8, 10, 12),
  .splitrule = "variance",
  .min.node.size = c(5, 10, 15)
)

set.seed(1234)
system.time({
  rf_model_2 <- train(
    formula(paste0("price ~ ", paste0(predictors_2, collapse = " + "))),
    data = data_train,
    method = "ranger",
    trControl = train_control,
    tuneGrid = tune_grid,
    importance = "impurity",
    na.action=na.exclude
  )
})

rf_model_2

# auto tuning first
# set.seed(1234)
# system.time({
#   rf_model_2auto <- train(
#     formula(paste0("price ~", paste0(predictors_2, collapse = " + "))),
#     data = data_train,
#     method = "ranger",
#     trControl = train_control,
#     importance = "impurity"
#   )
# })
# rf_model_2auto 
rf_model_2auto <- rf_model_2


# evaluate random forests -------------------------------------------------

results <- resamples(
  list(
    model_1  = rf_model_1,
    model_2  = rf_model_2,
    model_2b = rf_model_2auto
    
  )
)
summary(results)

# Save outputs -------------------------------------------------------

# Show Model B rmse shown with all the combinations
rf_tuning_modelB <- rf_model_2$results %>%
  dplyr::select(mtry, min.node.size, RMSE) %>%
  dplyr::rename(nodes = min.node.size) %>%
  spread(key = mtry, value = RMSE)


# Turning parameter choice 1
result_1 <- matrix(c(
  rf_model_1$finalModel$mtry,
  rf_model_2$finalModel$mtry,
  rf_model_2auto$finalModel$mtry,
  rf_model_1$finalModel$min.node.size,
  rf_model_2$finalModel$min.node.size,
  rf_model_2auto$finalModel$min.node.size
  
),
nrow=3, ncol=2,
dimnames = list(c("Model A", "Model B","Model B auto"),
                c("Min vars","Min nodes"))
)
kable(x = result_1, format = "latex", digits = 3) 

# Turning parameter choice 2
result_2 <- matrix(c(mean(results$values$`model_1~RMSE`),
                     mean(results$values$`model_2~RMSE`),
                     mean(results$values$`model_2b~RMSE`)
),
nrow=3, ncol=1,
dimnames = list(c("Model A", "Model B","Model B auto"),
                c(results$metrics[2]))
)


kable(x = result_2, digits = 3) 


#########################################################################################
#
# PART III
# MODEL DIAGNOSTICS -------------------------------------------------------
#
#########################################################################################


#########################################################################################
# Variable Importance Plots -------------------------------------------------------
#########################################################################################
# first need a function to calculate grouped varimp
group.importance <- function(rf.obj, groups) {
  var.imp <- as.matrix(sapply(groups, function(g) {
    sum(importance(rf.obj)[g], na.rm = TRUE)
  }))
  colnames(var.imp) <- "MeanDecreaseGini"
  return(var.imp)
}


# variable importance plot
# 1) full varimp plot, full
# 2) varimp plot grouped
# 3) varimp plot , top 10
# 4) varimp plot  w copy, top 10


rf_model_2_var_imp <- importance(rf_model_2$finalModel)/1000
rf_model_2_var_imp_df <-
  data.frame(varname = names(rf_model_2_var_imp),imp = rf_model_2_var_imp) %>%
  mutate(varname = gsub("f_neighbourhood_cleansed", "Borough:", varname) ) %>%
  mutate(varname = gsub("f_room_type", "Room type:", varname) ) %>%
  arrange(desc(imp)) %>%
  mutate(imp_percentage = imp/sum(imp))


##############################
# 1) full varimp plot, above a cutoff
##############################

# to have a quick look
plot(varImp(rf_model_2))

cutoff = 0.002

ggplot(rf_model_2_var_imp_df[rf_model_2_var_imp_df$imp > cutoff,],
                                  aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color=color[1], size=1.5) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color=color[1], size=1) +
  ylab("Importance (Percent)") +
  xlab("Variable Name") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bg() +
  theme(axis.text.x = element_text(size=6), axis.text.y = element_text(size=6),
        axis.title.x = element_text(size=6), axis.title.y = element_text(size=6))



##############################
# 2) full varimp plot, top 10 only
##############################


# have a version with top  vars only
ggplot(rf_model_2_var_imp_df[1:10,], aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color=color[1], size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color=color[1], size=0.75) +
  ylab("Importance (Percent)") +
  xlab("Variable Name") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bg() +
  theme(axis.text.x = element_text(size=4), axis.text.y = element_text(size=4),
        axis.title.x = element_text(size=4), axis.title.y = element_text(size=4))

##############################
# 2) varimp plot grouped
##############################
# grouped variable importance - keep binaries created off factors together

varnames <- rf_model_2$finalModel$xNames
f_neighbourhood_cleansed_varnames <- grep("f_neighbourhood_cleansed",varnames, value = TRUE)
f_property_type_varnames <- grep("f_property_type",varnames, value = TRUE)
f_room_type_varnames <- grep("f_room_type",varnames, value = TRUE)

groups <- list(f_neighbourhood_cleansed=f_neighbourhood_cleansed_varnames,
               f_property_type = f_property_type_varnames,
               f_room_type = f_room_type_varnames,
               n_days_since = "n_days_since",
               n_accommodates = "n_accommodates",
               n_beds = "n_beds")

rf_model_2_var_imp_grouped <- group.importance(rf_model_2$finalModel, groups)
rf_model_2_var_imp_grouped_df <- data.frame(varname = rownames(rf_model_2_var_imp_grouped),
                                            imp = rf_model_2_var_imp_grouped[,1])  %>%
  mutate(imp_percentage = imp/sum(imp))


  ggplot(rf_model_2_var_imp_grouped_df, aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color=color[1], size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color=color[1], size=0.7) +
  ylab("Importance (Percent)") +   xlab("Variable Name") +
  coord_flip() +
  # expand=c(0,0),
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bg() +
  theme(axis.text.x = element_text(size=4), axis.text.y = element_text(size=4),
        axis.title.x = element_text(size=4), axis.title.y = element_text(size=4))


#########################################################################################
# Partial Dependence Plots -------------------------------------------------------
#########################################################################################

# TODO
# : somehow adding scale screws up. ideadlly both graphs y beween 70 and 130,
# n:accom should be 1,7 by=1

# FIXME
# should be on holdout, right? pred.grid = distinct_(data_train, "), --> pred.grid = distinct_(data_holdout, )

pdp_n_acc <- pdp::partial(rf_model_2, pred.var = "n_accommodates", pred.grid = distinct_(data_holdout, "n_accommodates"), train = data_train)

  pdp_n_acc %>%
  autoplot( ) +
  geom_point(color=color[1], size=2) +
  geom_line(color=color[1], size=1) +
  ylab("Predicted price") +
  xlab("Accommodates (persons)") +
  scale_x_continuous(limit=c(1,7), breaks=seq(1,7,1))+
  theme_bg()

# describe(data_holdout_w_prediction$n_accommodates)


pdp_n_roomtype <- pdp::partial(rf_model_2, pred.var = "f_room_type", pred.grid = distinct_(data_holdout, "f_room_type"), train = data_train)

pdp_n_roomtype %>%
  autoplot( ) +
  geom_point(color=color[1], size=2) +
  ylab("Predicted price") +
  xlab("Room type") +
  scale_y_continuous(limits=c(0, 375), breaks=seq(0,10, by=1)) +
  theme_bg()


# Subsample performance: RMSE / mean(y) ---------------------------------------
# NOTE  we do this on the holdout set.

# ---- cheaper or more expensive flats - not used in book
data_holdout_w_prediction <- data_holdout %>%
  mutate(predicted_price = predict(rf_model_2, newdata = data_holdout))



######### create nice summary table of heterogeneity
a <- data_holdout_w_prediction %>%
  mutate(is_low_size = ifelse(n_accommodates <= 3, "small apt", "large apt")) %>%
  group_by(is_low_size) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = RMSE(predicted_price, price) / mean(price)
  )


b <- data_holdout_w_prediction %>%
  filter(f_neighbourhood_cleansed %in% c("Hollywood", "Santa Monica", "Downtown", "Venice", "Long Beach", "West Hollywood")) %>%
  group_by(f_neighbourhood_cleansed) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = rmse / mean_price
  )

c <- data_holdout_w_prediction %>%
  filter(f_property_type %in% c("Entire_apt", "Room_apt")) %>%
  group_by(f_property_type) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = rmse / mean_price
  )


d <- data_holdout_w_prediction %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = RMSE(predicted_price, price) / mean(price)
  )

# Save output
colnames(a) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(b) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(c) <- c("", "RMSE", "Mean price", "RMSE/price")
d<- cbind("All", d)
colnames(d) <- c("", "RMSE", "Mean price", "RMSE/price")

line1 <- c("Type", "", "", "")
line2 <- c("Apartment size", "", "", "")
line3 <- c("Borough", "", "", "")

result_3 <- rbind(line2, a, line1, c, line3, b, d) %>%
  transform(RMSE = as.numeric(RMSE), `Mean price` = as.numeric(`Mean price`),
            `RMSE/price` = as.numeric(`RMSE/price`))

options(knitr.kable.NA = '')
kable(x = result_3, format = "latex", booktabs=TRUE, linesep = "",digits = c(0,2,1,2), col.names = c("","RMSE","Mean price","RMSE/price")) %>%
options(knitr.kable.NA = NULL)

##########################################



#########################################################################################
#
# PART IV
# HORSERACE: compare with other models -----------------------------------------------
#
#########################################################################################



# OLS with dummies for area
# using model B

set.seed(1234)
system.time({
  ols_model <- train(
    formula(paste0("price ~", paste0(predictors_2, collapse = " + "))),
    data = data_train,
    method = "lm",
    trControl = train_control,
    na.action=na.exclude
  )
})

ols_model_coeffs <-  ols_model$finalModel$coefficients
ols_model_coeffs_df <- data.frame(
  "variable" = names(ols_model_coeffs),
  "ols_coefficient" = ols_model_coeffs
) %>%
  mutate(variable = gsub("`","",variable))

# * LASSO
# using extended model w interactions

set.seed(1234)
system.time({
  lasso_model <- train(
    formula(paste0("price ~", paste0(predictors_E, collapse = " + "))),
    data = data_train,
    method = "glmnet",
    preProcess = c("center", "scale"),
    tuneGrid =  expand.grid("alpha" = 1, "lambda" = seq(0.01, 0.25, by = 0.01)),
    trControl = train_control,
    na.action=na.exclude
  )
})

lasso_coeffs <- coef(
  lasso_model$finalModel,
  lasso_model$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var = "variable") %>%
  rename(lasso_coefficient = `1`)  # the column has a name "1", to be renamed

lasso_coeffs_non_null <- lasso_coeffs[!lasso_coeffs$lasso_coefficient == 0,]

regression_coeffs <- merge(ols_model_coeffs_df, lasso_coeffs_non_null, by = "variable", all=TRUE)
regression_coeffs %>%
  write.csv(file = paste0(output, "regression_coeffs.csv"))

# CART
set.seed(1234)
system.time({
  cart_model <- train(
    formula(paste0("price ~", paste0(predictors_2, collapse = " + "))),
    data = data_train,
    method = "rpart",
    tuneLength = 10,
    trControl = train_control,
    na.action=na.exclude
  )
})

fancyRpartPlot(cart_model$finalModel, sub = "")

# GBM  -------------------------------------------------------
gbm_grid <-  expand.grid(interaction.depth = c(1, 5, 10), # complexity of the tree
                         n.trees = (4:10)*50, # number of iterations, i.e. trees
                         shrinkage = 0.1, # learning rate: how quickly the algorithm adapts
                         n.minobsinnode = 20 # the minimum number of training set samples in a node to commence splitting
)


set.seed(1234)
system.time({
  gbm_model <- train(formula(paste0("price ~", paste0(predictors_2, collapse = " + "))),
                     data = data_train,
                     method = "gbm",
                     trControl = train_control,
                     na.action=na.exclude,
                     verbose = FALSE,
                     tuneGrid = gbm_grid)
})
gbm_model


# the next will be in final model, loads of tuning
gbm_grid2 <-  expand.grid(interaction.depth = c(1, 3, 5, 7, 9, 11), # complexity of the tree
                          n.trees = (1:10)*50, # number of iterations, i.e. trees
                          shrinkage = c(0.02, 0.05, 0.1, 0.15, 0.2), # learning rate: how quickly the algorithm adapts
                          n.minobsinnode = c(5,10,20,30) # the minimum number of training set samples in a node to commence splitting
)

# and get prediction rmse and add to next summary table

# ---- compare these models

final_models <-
  list("OLS" = ols_model,
       "LASSO (model w/ interactions)" = lasso_model,
       "CART" = cart_model,
       "Random forest (smaller model)" = rf_model_1,
       "Random forest" = rf_model_2,
       "Random forest (auto tuned)" = rf_model_2auto,
       "GBM (basic tuning)"  = gbm_model)

results <- resamples(final_models) %>% summary()


# Save output --------------------------------------------------------
# Model selection is carried out on this CV RMSE

result_4 <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~RMSE")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV RMSE" = ".")

kable(x = result_4, format = "latex", digits = 3, booktabs=TRUE, linesep = "") 




# evaluate preferred model on the holdout set -----------------------------

result_5 <- map(final_models, ~{
  RMSE(predict(.x, newdata = data_holdout), data_holdout[["price"]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("Holdout RMSE" = ".")
```
Table 5. shows the cross-validated test set RMSE values for the nine combinations of these tuning parameters. The lowest RMSE values of 44.2 is for 5 observations in the terminal nodes and 12 variables to consider at each split. 

```{r echo=F, warning=FALSE, warning=FALSE, message=FALSE}
rf_tuning_modelB %>% kable( digits = 4, caption = "Random Forest RMSE by tuning parameters") %>%
add_header_above(c(" ", "vars" = 3)) %>%  kable_classic(html_font = "Cambria") %>% kable_styling(full_width = T) 
```

#### Diagnostics: Variable Importance Plot
For random forest, it's hard to understand what patterns of association between y and x. However, with the help of variable importance plot, we can capture which x variables matter most for the prediction.

Displayed in below figure, the six variables with the largest average MSE reduction are presented: it shows us that number of accommodaitons, number of beds, property and room types are the top variables that matter most to apartmenr price in LA.
```{r echo=F, warning=FALSE, warning=FALSE, message=FALSE}
ggplot(rf_model_2_var_imp_df[1:10,], aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color=color[1], size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color=color[1], size=0.75) +
  ylab("Importance (Percent)") +
  xlab("Variable Name") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bg() +
  theme(axis.text.x = element_text(size=4), axis.text.y = element_text(size=4),
        axis.title.x = element_text(size=4), axis.title.y = element_text(size=4))
```
#### Diagnostics: Partial Dependence Plot
Another diagnostics tool that we use is Partial Dependence Plot (PDP), which can compute and visualize the patterns of association. This graph has values of the x variable on the horizontal axis and the values of y values on the vertical axis. From below two figures, we can see that apartment price and accommodation capacity have a linear positive relation. Room type does not affect price that much, though the most expensive type is hotel room.
```{r echo=F, warning=FALSE, warning=FALSE, message=FALSE ,out.width= "50%"}
pdp_n_acc %>%
  autoplot( ) +
  geom_point(color=color[1], size=2) +
  geom_line(color=color[1], size=1) +
  ylab("Predicted price") +
  xlab("Accommodates (persons)") +
  scale_x_continuous(limit=c(1,7), breaks=seq(1,7,1))+
  theme_bg()

pdp_n_roomtype %>%
  autoplot( ) +
  geom_point(color=color[1], size=2) +
  ylab("Predicted price") +
  xlab("Room type") +
  scale_y_continuous(limits=c(30, 210), breaks=seq(20,220, by=30)) +
  theme_bg()
```

# Summary
The goal of this passage is to predict apartment(2-6 people) price in Los Angles. The data are collected from Inside Airbnb LA region. We clean and transform data, and design OLS, LASSO and Random Forest Models to assist in our decision. BIC and RMSE are the criteria to assess each model. As a result, we esteem Model 7, the one with all variables and interactions among bread maker, trash compacter and wifi availability as the best one to predict price.

